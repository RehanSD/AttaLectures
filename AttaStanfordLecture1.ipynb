{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence Example\n",
    "In this notebook, we will go through an example using a Neural Network called Squeezenet. Squeezenet is a Neural Net based off of the Alexnet model. We use it in this example because it is lightweight and fast.\n",
    "\n",
    "In the following cell, we download a pretrained Squeezenet model from the PyTorch API. PyTorch is an ML framework that can be used to build neural nets. It also maintains a zoo of pretrained models that can be downloaded and used with little effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, torch, torchvision\n",
    "from torchvision import models, transforms\n",
    "squeezenet_model = models.squeezenet1_1(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the transformations that we will do on the inputs before passing them to the model. We will also download labels to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define the preproccessing on the images:\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "# Then we download the labels:\n",
    "labels = {int(key):value for (key, value)\n",
    "          in requests.get('https://s3.amazonaws.com/outcome-blog/imagenet/labels.json').json().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a predict function. Its input is an array of strings - either URL's or filenames - of images to run the model on. It returns an array of labels corresponding to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_torch_model(imgs, download=False):\n",
    "    import io\n",
    "    import PIL.Image\n",
    "    from io import BytesIO\n",
    "\n",
    "    # We first prepare a batch from `imgs`\n",
    "    img_tensors = []\n",
    "    for img in imgs:\n",
    "        if not download:\n",
    "            img_tensor = preprocess(PIL.Image.open(img))\n",
    "        else:\n",
    "            response = requests.get(img)\n",
    "            img_tensor = preprocess(PIL.Image.open(BytesIO(response.content)))\n",
    "        img_tensor.unsqueeze_(0)\n",
    "        img_tensors.append(img_tensor)\n",
    "    img_batch = torch.cat(img_tensors)\n",
    "    \n",
    "    # We perform a forward pass\n",
    "    with torch.no_grad():\n",
    "        model_output = squeezenet_model(img_batch)\n",
    "        \n",
    "    # Parse Result\n",
    "    img_labels = [labels[out.data.numpy().argmax()] for out in model_output]\n",
    "        \n",
    "    return img_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run it with some predownloaded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue is our cat's name. The last picture is an image of our cat.\n",
    "images = ['images/blue.JPG', 'images/cat.jpg', 'images/duck.jpg']\n",
    "from IPython.display import display, Image\n",
    "for img in images:\n",
    "    print('Output for', img)\n",
    "    display(Image(img, width=200, height=200))\n",
    "    print(predict_torch_model([img]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run it with some files we download from the web. We also note that AI can fail - while we got pretty good labels for the above images, we will see some test cases below where our results aren't as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue is our cat's name. The last picture is an image of our cat.\n",
    "download_images = ['https://techcrunch.com/wp-content/uploads/2015/02/shutterstock_175625024.jpg',\n",
    "                   'https://www.emmys.com/sites/default/files/styles/show_detail/public/disney-mickey-mouse-600x600.jpg']\n",
    "from IPython.display import display, Image\n",
    "for img in download_images:\n",
    "    print('Output for', img)\n",
    "    display(Image(img, width=200, height=200))\n",
    "    print(predict_torch_model([img], download=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
